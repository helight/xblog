+++
title = "spark1.3.1单机安装测试备忘"
date = "2015-06-09T03:31:45+08:00"
tags = ["storm","kernel"]
categories = ["storm"]
banner = "img/banners/banner-2.jpg"
draft = false
author = "helight"
authorlink = "https://helight.cn"
summary = ""
keywords = ["storm","kernel"]
+++

<div>1.下载,安装spark和scala:</div>
<div><a href="http://spark.apache.org/downloads.html" target="_blank" shape="rect">http://spark.apache.org/downloads.html</a></div>
<div>下载1.3.1的hadoop2.6版本. <a href="http://www.apache.org/dyn/closer.cgi/spark/spark-1.3.1/spark-1.3.1-bin-hadoop2.6.tgz" target="_blank" shape="rect">spark-1.3.1-bin-hadoop2.6.tgz</a></div>
<div></div>
<div>下载到本地之后直接解压即可:</div>
<div>helight@helight-xu:/data/spark$ tar zxf spark-1.3.1-bin-hadoop2.6.tgz</div>
<div></div>
<div><a href="http://www.scala-lang.org/download/" target="_blank" shape="rect">http://www.scala-lang.org/download/</a></div>
<div>下载scala,2.11.6,也是直接解压即可:</div>
<div>helight@helight-xu:/data/spark$ tar zxf scala-2.11.6.tgz</div>
<div></div>
<!--more-->
<div></div>
<div>安装spark和scala直接配置环境变量即可,可以直接写到 系统环境变量配置文件/etc/profile</div>
<div>或者写道用户配置文件中~/.bashrc中</div>
<div></div>
<div>export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/ <br clear="none" />export SCALA_HOME=/data/spark/scala-2.11.6 <br clear="none" />export PATH=$PATH:$JAVA_HOME/bin:$SCALA_HOME/bin</div>
<div></div>
<div>以上就是基本配置.</div>
<div></div>
<div>2.ssh本地互信登录配</div>
<div>这里和hadoop中的互信配置一样.</div>
<div>首先在机器上安装openssh-server和openssh-client.</div>
<div>helight@helight-xu:~/.ssh$ ssh-keygen</div>
<div>一直回车即可,不要输入任何东西</div>
<div>helight@helight-xu:~/.ssh$ ls<br clear="none" />id_rsa id_rsa.pub known_hosts</div>
<div>helight@helight-xu:~/.ssh$ cat id_rsa.pub &gt;authorized_keys</div>
<div>helight@helight-xu:~/.ssh$ ll<br clear="none" />total 24<br clear="none" />drwx------ 2 helight helight 4096 6月 8 15:06 ./<br clear="none" />drwxr-xr-x 23 helight helight 4096 6月 9 09:59 ../<br clear="none" />-rw------- 1 helight helight 400 6月 8 15:06 authorized_keys<br clear="none" />-rw------- 1 helight helight 1679 6月 8 15:06 id_rsa<br clear="none" />-rw-r--r-- 1 helight helight 400 6月 8 15:06 id_rsa.pub<br clear="none" />-rw-r--r-- 1 helight helight 444 6月 8 15:21 known_hosts</div>
<div>authorized_keys文件的权限设置为600,如上,这里或需要重新注销登录一下才可以无密码登录</div>
<div>helight@helight-xu:~/.ssh$ ssh localhost<br clear="none" />Welcome to Ubuntu 15.04 (GNU/Linux 3.19.0-20-generic x86_64)<br clear="none" /><br clear="none" />* Documentation: https://help.ubuntu.com/<br clear="none" /><br clear="none" />Last login: Mon Jun 8 15:20:51 2015 from localhost<br clear="none" />helight@helight-xu:~$</div>
<div></div>
<div>如上面的登录方式,则表示本机无密码登录ok了.</div>
<div></div>
<div>3.spark启动配置</div>
<div></div>
<div></div>
<div>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="DA">3.1 </span>配置<span lang="EN-US">spark-env.sh</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US">Copy</span>一份文件<span lang="EN-US">spark-env.sh.template</span>重命名为<span lang="EN-US">spark-env.sh</span>，在文件末尾添加

<div style="margin: 0px; padding: 0px; unicode-bidi: embed;">
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;">export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/ <br clear="none" />export SCALA_HOME=/data/spark/scala-2.11.6 <br clear="none" />export SPARK_MASTER_IP=helight-xu <br clear="none" />export SPARK_WORKER_CORES=1 <br clear="none" />export SPARK_WORKER_INSTANCES=1 <br clear="none" />export SPARK_WORKER_MEMORY=512M

</div>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;">可以看到，<span lang="EN-US">JAVA_HOME</span>和<span lang="EN-US">SCALA_HOME</span>都关联上了。
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;">赋予<span lang="EN-US">spark-env.sh</span>可执行权限

<div style="margin: 0px; padding: 0px; unicode-bidi: embed;">
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US">chmod 777 spark-env.sh</span>

</div>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US"> <span style="color: #336699;"><span style="background-color: #d5d5d5;">3.</span></span></span><span lang="DA">2    </span>配置<span lang="EN-US">slaves</span><span lang="EN-US"> </span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US">Copy</span>一份<span lang="EN-US">slaves.template</span>文件重命名为<span lang="EN-US">slaves</span>，添加机器名（或者<span lang="EN-US">ip</span>，不过<span lang="EN-US">ip</span>没试过）

<div style="margin: 0px; padding: 0px; unicode-bidi: embed;">
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US"># A Spark Worker will be started on each of the machines listed below.</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"># localhost <br clear="none" />helight-xu
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;">
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;">3.3配置<span lang="EN-US">spark-defaults.conf</span>

</div>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US">Copy</span>一份<span lang="EN-US">spark-defaults.conf.template</span>重命名为<span lang="EN-US">spark-defaults.conf</span>，把相关项打开（最后<span lang="EN-US">spark.executor.extraJavaOptions</span>这项我目前还不知道使用，待研究）。

<div style="margin: 0px; padding: 0px; unicode-bidi: embed;">
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US"># Default system properties included when running spark-submit.</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US"># This is useful for setting default environmental settings.</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US"> </span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US"># Example:</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;">spark.master                    spark://helight-xu:7077 <br clear="none" />spark.executor.memory 512m <br clear="none" />spark.eventLog.enabled true <br clear="none" />spark.eventLog.dir          /data/spark/spark-1.3.1-bin-hadoop2.6/logs/ <br clear="none" />spark.serializer                 org.apache.spark.serializer.KryoSerializer <br clear="none" />spark.driver.memory       512m
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="DA">3.4       </span>配置<span lang="EN-US">log4j.properties</span>

</div>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US">Copy</span>一份<span lang="EN-US">log4j.properties.template</span>文件重命名为<span lang="EN-US">log4j.properties</span>即可。内容如下：

<div style="margin: 0px; padding: 0px; unicode-bidi: embed;">
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US"># Set everything to be logged to the console
</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US">log4j.rootCategory=INFO, console</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US">log4j.appender.console=org.apache.log4j.ConsoleAppender</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US">log4j.appender.console.target=System.err</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US">log4j.appender.console.layout=org.apache.log4j.PatternLayout</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US">log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US"> </span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US"># Settings to quiet third party logs that are too verbose</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US">log4j.logger.org.eclipse.jetty=WARN</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US">log4j.logger.org.eclipse.jetty.util.component.AbstractLifeCycle=ERROR</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US">log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO</span>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span lang="EN-US">log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO</span>

</div>
<p style="margin: 0px 0px 1em; padding: 0px; unicode-bidi: embed; min-height: 1.8em;"><span style="line-height: 1.5;">3.5启动spark</span>

</div>
<div>helight@helight-xu:/data/spark/spark_hadoop$ ./sbin/start-all.sh <br clear="none" />starting org.apache.spark.deploy.master.Master, logging to /data/spark/spark-1.3.1-bin-hadoop2.6/sbin/../logs/spark-helight-org.apache.spark.deploy.master.Master-1-helight-xu.out<br clear="none" />helight-xu: starting org.apache.spark.deploy.worker.Worker, logging to /data/spark/spark-1.3.1-bin-hadoop2.6/sbin/../logs/spark-helight-org.apache.spark.deploy.worker.Worker-1-helight-xu.out<br clear="none" /><a href="mailto:helight@helight-xu:/data/spark/spark_hadoop$" target="_blank" shape="rect">helight@helight-xu:/data/spark/spark_hadoop$</a></div>
<div>查看启动进程:<br clear="none" />helight@helight-xu:/data/spark/spark_hadoop$ jps <br clear="none" />Picked up JAVA_TOOL_OPTIONS: -javaagent:/usr/share/java/jayatanaag.jar <br clear="none" />2625 Worker<br clear="none" />2758 Jps<br clear="none" />2410 Master<br clear="none" />helight@helight-xu:/data/spark/spark_hadoop$</div>
&nbsp;
<div>helight@helight-xu:/data/spark/spark_hadoop/conf$ ps axu|grep spark<br clear="none" />helight 2410 0.7 3.6 4064160 292772 pts/0 Sl 09:44 0:34 /usr/lib/jvm/java-8-openjdk-amd64//bin/java -cp /data/spark/spark-1.3.1-bin-hadoop2.6/sbin/../conf:/data/spark/spark-1.3.1-bin-hadoop2.6/lib/spark-assembly-1.3.1-hadoop2.6.0.jar:/data/spark/spark-1.3.1-bin-hadoop2.6/lib/datanucleus-core-3.2.10.jar:/data/spark/spark-1.3.1-bin-hadoop2.6/lib/datanucleus-api-jdo-3.2.6.jar:/data/spark/spark-1.3.1-bin-hadoop2.6/lib/datanucleus-rdbms-3.2.9.jar -Dspark.akka.logLifecycleEvents=true -Xms512m -Xmx512m org.apache.spark.deploy.master.Master --ip helight-xu --port 7077 --webui-port 8080<br clear="none" />helight 2625 0.7 3.3 4041960 270248 ? Sl 09:44 0:34 /usr/lib/jvm/java-8-openjdk-amd64//bin/java -cp /data/spark/spark-1.3.1-bin-hadoop2.6/sbin/../conf:/data/spark/spark-1.3.1-bin-hadoop2.6/lib/spark-assembly-1.3.1-hadoop2.6.0.jar:/data/spark/spark-1.3.1-bin-hadoop2.6/lib/datanucleus-core-3.2.10.jar:/data/spark/spark-1.3.1-bin-hadoop2.6/lib/datanucleus-api-jdo-3.2.6.jar:/data/spark/spark-1.3.1-bin-hadoop2.6/lib/datanucleus-rdbms-3.2.9.jar -Dspark.akka.logLifecycleEvents=true -Xms512m -Xmx512m org.apache.spark.deploy.worker.Worker spark://helight-xu:7077 --webui-port 8081<br clear="none" />helight 3849 0.0 0.0 11176 2648 pts/0 S+ 10:57 0:00 grep --color=auto spark<br clear="none" /><a href="mailto:helight@helight-xu:/data/spark/spark_hadoop/conf$" target="_blank" shape="rect">helight@helight-xu:/data/spark/spark_hadoop/conf$ </a></div>
<div></div>
<div>spark的web ui界面:</div>
<div>http://localhost:8080/</div>
<div> <a href="/zb_users/upload/2015/06/Screenshot-from-2015-06-09-105917.png"><img class="alignnone size-medium wp-image-901" src="/zb_users/upload/2015/06/Screenshot-from-2015-06-09-105917-300x169.png" alt="Screenshot from 2015-06-09 10:59:17" width="300" height="169" /></a></div>
<div></div>
<div><span style="line-height: 1.5;">3.6提交任务:</span></div>
<div>./bin/spark-submit --class org.zhwen.test.spark_test.WordCount --master spark://helight-xu:7077 /data/helight/workspace/spark_test/target/idata-task-project-0.0.1-xu-jar-with-dependencies.jar</div>
<div></div>
<div> <a href="/zb_users/upload/2015/06/Screenshot-from-2015-06-09-112944.png"><img class="alignnone size-medium wp-image-902" src="/zb_users/upload/2015/06/Screenshot-from-2015-06-09-112944-300x169.png" alt="Screenshot from 2015-06-09 11:29:44" width="300" height="169" /></a></div>
<div></div>