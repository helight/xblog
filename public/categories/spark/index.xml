<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark on 黑光技术</title>
    <link>http://www.helight.cn/categories/spark/</link>
    <description>Recent content in Spark on 黑光技术</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Thu, 29 Sep 2016 08:28:01 +0800</lastBuildDate><atom:link href="http://www.helight.cn/categories/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>使用Spark分析网站日志</title>
      <link>http://www.helight.cn/blog/2016/964/</link>
      <pubDate>Thu, 29 Sep 2016 08:28:01 +0800</pubDate>
      
      <guid>http://www.helight.cn/blog/2016/964/</guid>
      <description>&lt;p&gt;郁闷从昨天开始个人网站不断的发出告警504错误，登录机器看了一下是php-fpm报错，这个错误重启php-fpm后，几个小时就告警，快一年了都没什么问题，奇怪&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Spark分区器HashPartitioner详解和扩展</title>
      <link>http://www.helight.cn/blog/2015/951/</link>
      <pubDate>Mon, 30 Nov 2015 08:33:44 +0800</pubDate>
      
      <guid>http://www.helight.cn/blog/2015/951/</guid>
      <description>&lt;p&gt;在Spark中，存在两类分区函数：HashPartitioner和RangePartitioner，它们都是继承自Partitioner，主要提供了每个RDD有几个分区（numPartitions）以及对于给定的值返回一个分区ID（0~numPartitions-1），也就是决定这个值是属于那个分区的。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【转载】从Hadoop到Spark的架构实践</title>
      <link>http://www.helight.cn/blog/2015/918/</link>
      <pubDate>Tue, 29 Sep 2015 09:53:35 +0800</pubDate>
      
      <guid>http://www.helight.cn/blog/2015/918/</guid>
      <description>&lt;p&gt;当下，Spark已经在国内得到了广泛的认可和支持：2014年，Spark Summit China在北京召开，场面火爆；同年，Spark Meetup在北京、上海、深圳和杭州四个城市举办，其中仅北京就成功举办了5次，内容更涵盖Spark Core、Spark Streaming、Spark MLlib、Spark SQL等众多领域。而作为较早关注和引入Spark的移动互联网大数据综合服务公司，TalkingData也积极地参与到国内Spark社区的各种活动，并多次在Meetup中分享公司的Spark使用经验。本文则主要介绍TalkingData在大数据平台建设过程中，逐渐引入Spark，并且以Hadoop YARN和Spark为基础来构建移动大数据平台的过程。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>spark1.3.1单机安装测试备忘</title>
      <link>http://www.helight.cn/blog/2015/900/</link>
      <pubDate>Tue, 09 Jun 2015 03:31:45 +0800</pubDate>
      
      <guid>http://www.helight.cn/blog/2015/900/</guid>
      <description>&lt;h2 id=&#34;1下载安装spark和scala&#34;&gt;1.下载,安装spark和scala:&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://spark.apache.org/downloads.html&#34;&gt;http://spark.apache.org/downloads.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下载1.3.1的hadoop2.6版本. spark-1.3.1-bin-hadoop2.6.tgz&lt;/p&gt;
&lt;p&gt;下载到本地之后直接解压即可:&lt;/p&gt;
&lt;p&gt;helight@helight-xu:/data/spark$ tar zxf spark-1.3.1-bin-hadoop2.6.tgz&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.scala-lang.org/download/&#34;&gt;http://www.scala-lang.org/download/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下载scala,2.11.6,也是直接解压即可:&lt;/p&gt;
&lt;p&gt;helight@helight-xu:/data/spark$ tar zxf scala-2.11.6.tgz&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
